# Модуль импорта контента из Telegram

## Общее описание
Модуль предназначен для автоматизированного сбора контента из Telegram-каналов.
Использует библиотеку **Telethon**.
Архитектура:
- **Universal Client**: Отвечает за соединение, итерацию по истории, скачивание файлов.
- **BaseAdapter**: Абстрактный класс для нормализации данных.
- **Concrete Adapters**: Реализации для специфичных каналов (первый тест: `popyachsa`).

## Требования

### 1. Конфигурация и Сессии
- **Библиотека**: `Telethon`.
- **Сессии**: Используются готовые файлы сессий (`.session`).
  - Путь: `data/session/{session_name}.session`.
  - При старте скрипт загружает указанную сессию.
- **Credentials**: `API_ID`, `API_HASH` из `.env`.

### 2. Хранение данных (Output)

#### Файловая структура
Медиа-файлы сохраняются в папку `data/incoming`:
```text
data/incoming/
  └── {channel_name}/
      └── {YYYY-MM-DD_HH-mm-ss}/
            ├── original_filename.jpg
            ├── video.mp4
            └── ...
```
- Имена файлов: **Оригинальные** (как в Telegram).
- Единица контента: Папка с файлами (пост).

#### База данных (Metadata)
- **СУБД**: SQLite.
- **Цель**: Хранение метаданных для импорта и предотвращение дубликатов.
- **Модель данных** (Pydantic-like schema):
  - `channel_name` (str)
  - `post_id` (int) - ID поста в канале (для дедупликации).
  - `date` (datetime)
  - `model_name` (str) - *заполняется адаптером*
  - `set_name` (str, optional) - *заполняется адаптером*
  - `content_format` (str) - 'photo' / 'video' / 'mixed'
  - `file_path` (str) - путь к папке с контентом (относительный или абсолютный).

### 3. Логика работы (Workflow)

#### Pagination Flow
1. Клиент заходит в канал.
2. Скачивает посты **пачками** (например, по 10 штук).
3. Порядок: От **новых к старым**.
4. Проверка на дубликаты:
   - Если пост уже есть в БД (проверка по `channel_name` + `post_id`), он пропускается?
   - *Уточненная логика*: Если встречаем пост, который уже есть, значит, более старые тоже, скорее всего, есть. Но так как могут удалять посты, лучше просто идти по истории и пропускать существующие, пока не достигнем "глубины" проверки или не уткнемся в "очень старые".
   - *Для старта*: Просто итерация по N последних постов, скачивание тех, которых нет в БД.

### 4. Архитектура Адаптеров
- **`BaseAdapter`**:
  - Метод `extract_metadata(message) -> NormalizedData`.
  - Метод `filter(message) -> bool` (нужен ли этот пост).
- **Логика**:
  - Клиент получает `Message` от Telethon.
  - Передает в Адаптер.
  - Адаптер парсит текст/caption, извлекает `model_name`, `set_name` (если есть).
  - Адаптер решает, качать или нет (фильтрация рекламы, мусора).
  - Если ОК -> Клиент качает медиа и пишет запись в SQLite.

---

## План разработки
1.  Настройка окружения (`poetry`/`pip`, `.env`).
2.  Реализация `TelegramClientWrapper` (подключение, итерация).
3.  Создание БД SQLite и модели данных.
4.  Реализация `BaseAdapter` и `PopyachsaAdapter` (тестовый).
5.  Сборка воедино: Скрипт запуска импорта `python run_import.py --channel popyachsa`.
